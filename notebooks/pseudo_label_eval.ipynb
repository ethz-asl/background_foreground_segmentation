{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from bfseg.utils.metrics import IgnorantBalancedMeanIoU, IgnorantMeanIoU, IgnorantBalancedAccuracyMetric, IgnorantAccuracyMetric\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from bfseg.data.meshdist.dataLoader import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "def oneMetricIteration(metric, label, pred):\n",
    "  \"\"\" Helper function to get the result from one prediction \"\"\"\n",
    "  metric.update_state(label, pred)\n",
    "  res = metric.result().numpy()\n",
    "  metric.reset_states()\n",
    "  return res\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate(images, masked = False, assignForeground = False):\n",
    "    \"\"\" evaluates the given pseudo labels\"\"\"\n",
    "    iam_valid = IgnorantAccuracyMetric()\n",
    "    ibm_valid = IgnorantBalancedAccuracyMetric()\n",
    "    MIOUM_valid = IgnorantMeanIoU()\n",
    "\n",
    "    for gt, img in images:\n",
    "        img_np = np.asarray(Image.open(img))\n",
    "        pseudo_masked = img_np\n",
    "        pseudo_labels_unknown_background = img_np > 0\n",
    "        pseudo_labels_unknown_fg = img_np > 1\n",
    "\n",
    "        img_np = np.asarray(Image.open(gt).resize((img_np.shape[1], img_np.shape[0]), Image.NEAREST))\n",
    "        gt_labels = np.sum(img_np, axis = -1) > 0\n",
    "\n",
    "\n",
    "\n",
    "        gt_labels_ignorant = gt_labels * 2\n",
    "        if masked:\n",
    "            gt_labels_ignorant[pseudo_masked == 1] = 1\n",
    "\n",
    "        # Update Accuracy metrics\n",
    "        pseudo_labels_cat = tf.keras.utils.to_categorical(\n",
    "            tf.convert_to_tensor(pseudo_labels_unknown_fg if assignForeground else pseudo_labels_unknown_background), num_classes=3, dtype='float32'\n",
    "        )\n",
    "\n",
    "        iam_valid.update_state(gt_labels_ignorant, pseudo_labels_cat)\n",
    "        ibm_valid.update_state(gt_labels_ignorant, pseudo_labels_cat)\n",
    "        MIOUM_valid.update_state(gt_labels_ignorant, pseudo_labels_cat)\n",
    "\n",
    "    iam_valid_value = iam_valid.result().numpy()\n",
    "    MIOUM_valid_value = MIOUM_valid.result().numpy()\n",
    "    ibm_valid_value = ibm_valid.result().numpy()\n",
    "\n",
    "    print(\"Accuracy on validation set:\", iam_valid_value)\n",
    "    print(\"Balanced Accuracy on validation set:\", ibm_valid_value)\n",
    "    print(\"mIoU on validation set:\", MIOUM_valid_value)\n",
    "    capture_values.append((iam_valid_value, ibm_valid_value,MIOUM_valid_value))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL = DataLoader(\n",
    "          \"/home/rene/cla_dataset/fused\", [480, 624],\n",
    "          validationDir=\"/home/rene/hiveLabels\",\n",
    "          validationMode=\"CLA\",\n",
    "          batchSize=1,\n",
    "          loadDepth=False,\n",
    "          cropOptions={\n",
    "              'top': 0,\n",
    "              'bottom': 0\n",
    "          })\n",
    "validLabels = DL.validationLabels\n",
    "\n",
    "images_fused = []\n",
    "for label in validLabels:\n",
    "    # only use images where we have pseudo labels for\n",
    "    regex_pattern = \"(.+)_(\\d+\\.\\d+)_semseg\\.png\"\n",
    "    match = re.search(regex_pattern, os.path.basename(label))\n",
    "    cam = match.group(1)\n",
    "    ts = float(match.group(2))\n",
    "    info_file = os.path.join(\"/home/rene/cla_dataset/fused\", f\"{cam}_info.txt\")\n",
    "    if(np.sum(pd.read_csv(info_file, header=None, sep=',|;', engine=\"python\").to_numpy()[:,-2] == ts)):\n",
    "        idx = np.argmax(pd.read_csv(info_file, header=None, sep=',|;', engine=\"python\").to_numpy()[:,-2] == ts)\n",
    "        img_path = [ l for l in DL.labels if cam + \"_img_\"+(str(idx).zfill(4)) in l][0]\n",
    "        images_fused.append((label, img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL = DataLoader(\n",
    "          \"/home/rene/cla_dataset/sp_slac\", [480, 624],\n",
    "          validationDir=\"/home/rene/hiveLabels\",\n",
    "          validationMode=\"CLA\",\n",
    "          batchSize=1,\n",
    "          loadDepth=False,\n",
    "          cropOptions={\n",
    "              'top': 0,\n",
    "              'bottom': 0\n",
    "          })\n",
    "validLabels = DL.validationLabels\n",
    "\n",
    "images_slac = []\n",
    "for label in validLabels:\n",
    "    # only use images where we have pseudo labels for\n",
    "    regex_pattern = \"(.+)_(\\d+\\.\\d+)_semseg\\.png\"\n",
    "    #print(os.path.basename(label))\n",
    "    match = re.search(regex_pattern, os.path.basename(label))\n",
    "    cam = match.group(1)\n",
    "    ts = float(match.group(2))\n",
    "    info_file = os.path.join(\"/home/rene/cla_dataset/fused\", f\"{cam}_info.txt\")\n",
    "    if(np.sum(pd.read_csv(info_file, header=None, sep=',|;', engine=\"python\").to_numpy()[:,-2] == ts)):\n",
    "        idx = np.argmax(pd.read_csv(info_file, header=None, sep=',|;', engine=\"python\").to_numpy()[:,-2] == ts)\n",
    "        img_path = [ l for l in DL.labels if cam + \"_img_\"+(str(idx).zfill(4)) in l][0]\n",
    "        images_slac.append((label, img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL = DataLoader(\n",
    "          \"/home/rene/cla_dataset/watershed\", [480, 624],\n",
    "          validationDir=\"/home/rene/hiveLabels\",\n",
    "          validationMode=\"CLA\",\n",
    "          batchSize=1,\n",
    "          loadDepth=False,\n",
    "          cropOptions={\n",
    "              'top': 0,\n",
    "              'bottom': 0\n",
    "          })\n",
    "validLabels = DL.validationLabels\n",
    "\n",
    "images_watershed = []\n",
    "for label in validLabels:\n",
    "    # only use images where we have pseudo labels for\n",
    "    regex_pattern = \"(.+)_(\\d+\\.\\d+)_semseg\\.png\"\n",
    "    match = re.search(regex_pattern, os.path.basename(label))\n",
    "    cam = match.group(1)\n",
    "    ts = float(match.group(2))\n",
    "    info_file = os.path.join(\"/home/rene/cla_dataset/fused\", f\"{cam}_info.txt\")\n",
    "    if(np.sum(pd.read_csv(info_file, header=None, sep=',|;', engine=\"python\").to_numpy()[:,-2] == ts)):\n",
    "        idx = np.argmax(pd.read_csv(info_file, header=None, sep=',|;', engine=\"python\").to_numpy()[:,-2] == ts)\n",
    "        img_path = [ l for l in DL.labels if cam + \"_img_\"+(str(idx).zfill(4)) in l][0]\n",
    "        images_watershed.append((label, img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_watershed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_values = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Labels - Masking out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watershed\n",
      "Accuracy on validation set: 0.8029897\n",
      "Balanced Accuracy on validation set: 0.7087654\n",
      "mIoU on validation set: 0.60091454\n",
      "slac\n",
      "Accuracy on validation set: 0.84657276\n",
      "Balanced Accuracy on validation set: 0.7886652\n",
      "mIoU on validation set: 0.6841648\n",
      "combined\n",
      "Accuracy on validation set: 0.8665399\n",
      "Balanced Accuracy on validation set: 0.78035957\n",
      "mIoU on validation set: 0.6931578\n"
     ]
    }
   ],
   "source": [
    "print(\"watershed\")\n",
    "evaluate(images_watershed, masked = True)\n",
    "\n",
    "print(\"slac\")\n",
    "evaluate(images_slac, masked = True)\n",
    "\n",
    "print(\"combined\")\n",
    "evaluate(images_fused, masked = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Labels - Assign BG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watershed\n",
      "Accuracy on validation set: 0.7737981\n",
      "Balanced Accuracy on validation set: 0.6461298\n",
      "mIoU on validation set: 0.5300385\n",
      "slac\n",
      "Accuracy on validation set: 0.75885826\n",
      "Balanced Accuracy on validation set: 0.6134369\n",
      "mIoU on validation set: 0.48906723\n",
      "combined\n",
      "Accuracy on validation set: 0.75086814\n",
      "Balanced Accuracy on validation set: 0.5890446\n",
      "mIoU on validation set: 0.46131268\n"
     ]
    }
   ],
   "source": [
    "print(\"watershed\")\n",
    "evaluate(images_watershed, masked = False,assignForeground = False)\n",
    "\n",
    "print(\"slac\")\n",
    "evaluate(images_slac, masked = False,assignForeground = False)\n",
    "\n",
    "print(\"combined\")\n",
    "evaluate(images_fused, masked = False,assignForeground = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Labels - Assign FG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watershed\n",
      "Accuracy on validation set: 0.63819784\n",
      "Balanced Accuracy on validation set: 0.6389101\n",
      "mIoU on validation set: 0.4503584\n",
      "slac\n",
      "Accuracy on validation set: 0.51139015\n",
      "Balanced Accuracy on validation set: 0.60945547\n",
      "mIoU on validation set: 0.34353313\n",
      "combined\n",
      "Accuracy on validation set: 0.5115174\n",
      "Balanced Accuracy on validation set: 0.61108446\n",
      "mIoU on validation set: 0.3436405\n"
     ]
    }
   ],
   "source": [
    "print(\"watershed\")\n",
    "evaluate(images_watershed, masked = False,assignForeground = True)\n",
    "\n",
    "print(\"slac\")\n",
    "evaluate(images_slac, masked = False,assignForeground = True)\n",
    "\n",
    "print(\"combined\")\n",
    "evaluate(images_fused, masked = False,assignForeground = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8029897, 0.7087654, 0.60091454),\n",
       " (0.84657276, 0.7886652, 0.6841648),\n",
       " (0.8665399, 0.78035957, 0.6931578),\n",
       " (0.7737981, 0.6461298, 0.5300385),\n",
       " (0.75885826, 0.6134369, 0.48906723),\n",
       " (0.75086814, 0.5890446, 0.46131268),\n",
       " (0.63819784, 0.6389101, 0.4503584),\n",
       " (0.51139015, 0.60945547, 0.34353313),\n",
       " (0.5115174, 0.61108446, 0.3436405)]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capture_values # watershed, slac, combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(80.3, 70.9, 60.1),\n",
       " (84.7, 78.9, 68.4),\n",
       " (86.7, 78.0, 69.3),\n",
       " (77.4, 64.6, 53.0),\n",
       " (75.9, 61.3, 48.9),\n",
       " (75.1, 58.9, 46.1),\n",
       " (63.8, 63.9, 45.0),\n",
       " (51.1, 60.9, 34.4),\n",
       " (51.2, 61.1, 34.4)]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(round(v[0]*100,1),round(v[1]*100,1),round(v[2]*100,1)) for v in capture_values]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}